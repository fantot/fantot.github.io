---
title: "NIM-STGCN: Differentiable motion decomposition for egocentric pedestrian trajectory prediction"
collection: publications
category: manuscripts
permalink: /publication/2025-11-26-paper-1
excerpt: 'We present NIM-STGCN, a unified framework whose core contribution is a differentiable view normalization(GVN) that couples an enhanced differentiable PnP layer (ED-PnP) with an warp to align past observations into a single virtual static camera frame. Because GVN is trained end-to-end, forecasting losses back-propagate to pose estimation, yielding geometrically cleaner inputs. On the normalized histories, a lightweight Gated Convolutional Imputation Module (GCIM) recovers missing bounding-box measurements while preserving observed entries, and an efficient spatio-temporal GCN encodes agent dynamics and interactions (optionally augmented by a physics-guided kinematics–interaction prior, PKIM). A Gaussian-mixture predictor produces multi-modal futures and is optimized with a sequence-level negative log-likelihood together with a time-weighted position loss. '
date: 2025-11-26
venue: 'Complex Intell. Syst. '
slidesurl: 'http://academicpages.github.io/files/slides3.pdf'
paperurl: '[https://link.springer.com/article/10.1007/s40747-025-02068-4](https://link.springer.com/article/10.1007/s40747-025-02190-3)'
citation: 'Fang, B., Qin, F. & Wang, Y. ARP-STGCN: a fast attraction–repulsion-potential based spatio-temporal graph convolutional network with imputation for pedestrian trajectory prediction. Complex Intell. Syst. 11, 469 (2025). https://doi.org/10.1007/s40747-025-02068-4'
---

Pedestrian trajectory prediction from egocentric monocular video is hindered by camera motion, intermittent occlusions, and complex social interactions. We present NIM-STGCN, a unified framework whose core contribution is a differentiable view normalization(GVN) that couples an enhanced differentiable PnP layer (ED-PnP) with an warp to align past observations into a single virtual static camera frame. Because GVN is trained end-to-end, forecasting losses back-propagate to pose estimation, yielding geometrically cleaner inputs. On the normalized histories, a lightweight Gated Convolutional Imputation Module (GCIM) recovers missing bounding-box measurements while preserving observed entries, and an efficient spatio-temporal GCN encodes agent dynamics and interactions (optionally augmented by a physics-guided kinematics–interaction prior, PKIM). A Gaussian-mixture predictor produces multi-modal futures and is optimized with a sequence-level negative log-likelihood together with a time-weighted position loss. Extensive experiments on the JAAD and PIE benchmarks show that NIM-STGCN reduces Average Displacement Error (ADE) and Final Displacement Error (FDE) by 12–18 % compared to state-of-the-art methods.network (STGCN) to model dynamic interactions between pedestrians, while incorporating scene features to account for environmental context. Additionally, we introduce a Weighted Position Loss function to emphasize accurate prediction in later time steps, ensuring that cumulative errors are minimized. Our approach outperforms existing methods in terms of both prediction accuracy and computational efficiency, achieving significantly lower Average Displacement Error and Final Displacement Error across multiple benchmarks, including the ETH/UCY dataset and SDD dataset. Moreover, ARP-STGCN consistently demonstrates faster inference times compared to state-of-the-art methods, making it suitable for real-time applications.
